{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import fitz\n",
    "import json\n",
    "import shutil\n",
    "import string\n",
    "from sys import stdin\n",
    "import os\n",
    "import re\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#needs to be number increasing \n",
    "#remove page-page            \n",
    "def remove_slash(lst):\n",
    "    for i in range(1,len(lst)-1):\n",
    "        if lst[i]==\"–\" and lst[i+1].isalpha() and lst[i-1].isalpha():\n",
    "            return lst[0:i]+lst[i+2:]\n",
    "        if lst[i]==\"-\" and lst[i+1].isalpha() and lst[i-1].isalpha():\n",
    "            return lst[0:i]+lst[i+2:]\n",
    "    return lst\n",
    "\n",
    "def clean_number(str):\n",
    "    ans = \"\"\n",
    "    for i in str:\n",
    "        if i.isdigit():\n",
    "            ans += i\n",
    "    return ans\n",
    "\n",
    "def remove_number(str1,pos_num):\n",
    "    line = str1.split(\" \")\n",
    "    line = [i for i in line if i!=\"\"]\n",
    "    line = remove_slash(line)\n",
    "    if(pos_num==0):\n",
    "        for i in range(0,len(line)):\n",
    "            if (not line[i].isnumeric()) and any(c.isalpha() for c in line[i]) :\n",
    "            #if (not line[i].isnumeric()):\n",
    "                return \" \".join(line[i:]).replace(\".\",\"\"),clean_number(line[pos_num])\n",
    "    else:\n",
    "        for i in range(len(line)-1,-1,-1):\n",
    "            if (not line[i].isnumeric()) and any(c.isalpha() for c in line[i]):\n",
    "            #if (not line[i].isnumeric()):\n",
    "                return \" \".join(line[0:i+1]).replace(\".\",\"\"),clean_number(line[pos_num])\n",
    "\n",
    "#if start with content, search with less requirement \n",
    "def process_tolerant(num,lst):\n",
    "    index = num\n",
    "    toc = []\n",
    "    toc_page = []\n",
    "    sub_dir = 0\n",
    "    bad_line = 0\n",
    "    pos_num = None\n",
    "    for i in range(min(10,len(lst)-index-1)):\n",
    "        index += 1\n",
    "        if_start,pos_num = toc_start(lst[index])\n",
    "        if(if_start):\n",
    "            break\n",
    "        elif i==9:\n",
    "            return None,0,0\n",
    "    while(sub_dir<=5 and index<len(lst)):\n",
    "        status,_ = toc_form_check(lst[index],pos_num)\n",
    "        if(status):\n",
    "            sub_dir = 0 \n",
    "            content,number = remove_number(lst[index],pos_num)\n",
    "            toc.append(content)\n",
    "            toc_page.append(number)\n",
    "        else:\n",
    "            sub_dir += 1\n",
    "            bad_line += 1 \n",
    "        #toc.append(lst[index])\n",
    "        index += 1\n",
    "    if(index-num-bad_line>3):\n",
    "        #return toc[0:len(toc)-sub_dir]\n",
    "        return toc,index-sub_dir-1,toc_page\n",
    "    else:\n",
    "        return None,0,0\n",
    " \n",
    "#search continuous appearing numbers\n",
    "def process(num,lst,pos_num):\n",
    "    index = num\n",
    "    toc = []\n",
    "    toc_page = []\n",
    "    sub_dir = 0\n",
    "    bad_line = 0\n",
    "    prev_page = -1\n",
    "    while(sub_dir<=5 and index<len(lst)):\n",
    "        if \"contents\" in lst[index].lower() and toc_page !=[] and len(toc_page)<2:\n",
    "            toc_page.pop()\n",
    "            toc.pop()\n",
    "            index += 1\n",
    "            continue\n",
    "        status,cur_page = toc_form_check(lst[index],pos_num)\n",
    "        if(status):\n",
    "            if(cur_page>=prev_page):\n",
    "                prev_page = cur_page\n",
    "                sub_dir = 0\n",
    "                content,number = remove_number(lst[index],pos_num)\n",
    "                toc.append(content)\n",
    "                toc_page.append(number)\n",
    "            else:\n",
    "                sub_dir += 1\n",
    "                bad_line += 1                 \n",
    "        else:\n",
    "            sub_dir += 1\n",
    "            bad_line += 1 \n",
    "        #toc.append(lst[index])\n",
    "        index += 1\n",
    "    if(index-num-bad_line>5):\n",
    "        #return toc[0:len(toc)-sub_dir]\n",
    "        return toc,index-sub_dir-1,toc_page\n",
    "    else:\n",
    "        return None,0,0\n",
    "\n",
    "#check if satify the format of ToC\n",
    "def toc_form_check(str,pos_num = None):\n",
    "    #str1 = re.sub(r'[^\\w\\s]','',str)\n",
    "    str1 = str.replace(\".\",\"\")\n",
    "    str1 = str1.replace(\"•\",\"\")\n",
    "    line = str1.split(\" \")\n",
    "    line = [i for i in line if i!=\"\"]\n",
    "    line = remove_slash(line)\n",
    "    if line==[]:\n",
    "        return False,0\n",
    "    alpha = 0\n",
    "    number = 0\n",
    "    for word in line:\n",
    "        if word.isalpha():\n",
    "            alpha += 1\n",
    "        if word.isnumeric():\n",
    "            number += 1\n",
    "    #if alpha==len(line)-1 and number ==1 and alpha >0 and len(line)<10 and line[pos_num].isnumeric():\n",
    "    if number>=1 and alpha>=1 and len(line)<15 and line[pos_num].isnumeric():\n",
    "        try:\n",
    "            if int(line[pos_num])<150 and int(line[pos_num])>0:\n",
    "                return True,int(line[pos_num])\n",
    "        except:\n",
    "            return False,0\n",
    "    return False,0\n",
    "\n",
    "#Check if looks like start of ToC\n",
    "def toc_start(str):\n",
    "    str = re.sub(r'[^\\w\\s]','',str)\n",
    "    line = str.split(\" \")\n",
    "    line = [i for i in line if i!=\"\"]\n",
    "    line = remove_slash(line)\n",
    "    if line==[]:\n",
    "        return False,None\n",
    "    alpha = 0\n",
    "    number = 0\n",
    "    for word in line:\n",
    "        if word.isalpha():\n",
    "            alpha += 1\n",
    "        if word.isnumeric():\n",
    "            number += 1\n",
    "    num_pos = None\n",
    "    if line[0].isnumeric():\n",
    "        num_pos = 0\n",
    "    elif line[-1].isnumeric():\n",
    "        num_pos = -1\n",
    "    else:\n",
    "        return False,None\n",
    "    #if alpha==len(line)-1 and number ==1 and alpha >0 and len(line)<10:\n",
    "    if number>=1 and alpha>=1 and len(line)<15:\n",
    "        try:\n",
    "            val = int(line[num_pos])\n",
    "            if (val<50):\n",
    "                return True,num_pos\n",
    "        except:\n",
    "            return False,None\n",
    "    return False,None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_page(key,lst,start_pos,page_hint):\n",
    "    prev_pos = start_pos\n",
    "    \n",
    "    key_index = 0\n",
    "    page_pos = []\n",
    "    count = start_pos\n",
    "\n",
    "    while(count<len(lst)-100 and key_index < len(key)): \n",
    "        if key[key_index].lower() in lst[count].lower():\n",
    "        #if match(key[key_index].lower(),lst[count].lower()):\n",
    "            #if page_pos!=[] and page_pos[-1]!=None and count <= page_pos[-1]+5:       \n",
    "            if page_pos!=[] and page_pos[-1]!=None and count <= page_pos[-1]+int(page_hint[key_index])-int(page_hint[key_index-1]):\n",
    "                page_pos.pop()\n",
    "                key_index -= 1\n",
    "            else:\n",
    "                prev_pos = count\n",
    "                page_pos.append(count)\n",
    "                key_index +=1 \n",
    "        count +=1\n",
    "        \n",
    "        if page_pos!=[] and page_pos[0]!=None:\n",
    "            diff = page_pos[0]\n",
    "        else:\n",
    "            diff = start_pos\n",
    "            \n",
    "        if(key_index<len(key) and key_index>0 and (count >(len(lst)-diff)*int(page_hint[key_index])*1.2/int(page_hint[-1]))):\n",
    "            count = prev_pos\n",
    "            page_pos.append(None)\n",
    "            key_index+=1  \n",
    "        elif(count == len(lst)-100 and key_index<len(key)):\n",
    "            count = prev_pos\n",
    "            page_pos.append(None)\n",
    "            key_index+=1\n",
    "        \n",
    "    return page_pos\n",
    "\n",
    "def split_page_without_pagehint(key,lst,start_pos):\n",
    "    prev_pos = start_pos\n",
    "    \n",
    "    key_index = 0\n",
    "    page_pos = []\n",
    "    count = start_pos\n",
    "    while(count<len(lst)-100 and key_index < len(key)): \n",
    "        if key[key_index].lower() in lst[count].lower():\n",
    "        #if match(key[key_index].lower(),lst[count].lower()):\n",
    "            #if page_pos!=[] and page_pos[-1]!=None and count <= page_pos[-1]+5:       \n",
    "            if page_pos!=[] and page_pos[-1]!=None and count <= page_pos[-1]+2:\n",
    "                page_pos.pop()\n",
    "                key_index -= 1\n",
    "            else:\n",
    "                prev_pos = count\n",
    "                page_pos.append(count)\n",
    "                key_index +=1 \n",
    "        count +=1\n",
    "        \n",
    "\n",
    "        if(count == len(lst)-100 and key_index<len(key)):\n",
    "            count = prev_pos\n",
    "            #count = start_pos\n",
    "            page_pos.append(None)\n",
    "            key_index+=1\n",
    "        \n",
    "    return page_pos\n",
    "\n",
    "\n",
    "def search_page_helper(key,lst,start_pos):\n",
    "    prev_pos = start_pos\n",
    "    \n",
    "    key_index = 0\n",
    "    page_pos = []\n",
    "    count = start_pos\n",
    "\n",
    "    while(count<len(lst)-100 and key_index < len(key)): \n",
    "        if key[key_index] in lst[count].lower().split(\" \"):\n",
    "\n",
    "            if page_pos!=[] and page_pos[-1]!=None and count <= page_pos[-1]+int(key[key_index])-int(key[key_index-1]):\n",
    "                page_pos.pop()\n",
    "                key_index -= 1\n",
    "            else:\n",
    "                prev_pos = count\n",
    "                page_pos.append(count)\n",
    "                key_index +=1 \n",
    "\n",
    "        count +=1\n",
    "\n",
    "        if(key_index<len(key) and (count >len(lst)*int(key[key_index])*1.2/int(key[-1]))):\n",
    "            count = prev_pos\n",
    "            #count = start_pos\n",
    "            page_pos.append(None)\n",
    "            key_index+=1\n",
    "        elif(key_index<len(key) and count == len(lst)-100):\n",
    "            count = prev_pos\n",
    "            #count = start_pos\n",
    "            page_pos.append(None)\n",
    "            key_index+=1\n",
    "\n",
    "    return page_pos\n",
    "\n",
    "def remove_zero(lst):\n",
    "    new_lst = []\n",
    "    for i in lst:\n",
    "        if i[0]==\"0\":\n",
    "            new_lst.append(i[1:])\n",
    "        else:\n",
    "            new_lst.append(i)\n",
    "    return new_lst\n",
    "\n",
    "def search_page(key,lst,start_pos):\n",
    "     ori = search_page_helper(key,lst,start_pos)\n",
    "     clean =  search_page_helper(remove_zero(key),lst,start_pos)\n",
    "     num = 0\n",
    "     for i in ori:\n",
    "        if i==None:\n",
    "            num +=1\n",
    "     num1 = 0\n",
    "     for i in clean:\n",
    "        if i== None:\n",
    "            num1 +=1\n",
    "     if num>num1:\n",
    "        return clean\n",
    "     else:\n",
    "        return ori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match(str1,str2):\n",
    "    lst1 = str1.lower().split(\" \")\n",
    "    lst2 = str2.lower().split(\" \")\n",
    "    find = 0\n",
    "    unfind = 0\n",
    "    for i in lst1:\n",
    "        if i in lst2:\n",
    "            find += 1\n",
    "        else:\n",
    "            unfind +=1\n",
    "    if unfind==1 or unfind == 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def find_next(pos,lst,end):\n",
    "    for i in range(pos,len(lst)):\n",
    "        if lst[i]!=None:\n",
    "            return lst[i]\n",
    "    return end\n",
    "        \n",
    "def weak_search(key,page_pos,lst,start_pos):\n",
    "    prev = start_pos\n",
    "    next_page = 0\n",
    "    for i in range(len(page_pos)):\n",
    "        if page_pos[i]==None:\n",
    "            next_page = find_next(i,page_pos,len(lst))\n",
    "            for index in range(prev+2,next_page):\n",
    "                if match(key[i],lst[index]):\n",
    "                    page_pos[i] = index\n",
    "                    prev = index\n",
    "                    break\n",
    "        else:\n",
    "            prev = page_pos[i]\n",
    "    return page_pos\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_next_with_index(pos,lst,end):\n",
    "    for i in range(pos,len(lst)):\n",
    "        if lst[i]!=None:\n",
    "            return lst[i],i\n",
    "    return end,len(lst)\n",
    "\n",
    "def split_into_half(lst,file,start_pos):\n",
    "    prev = None\n",
    "    next_page = 0\n",
    "    for i in range(len(lst)):\n",
    "        if lst[i] == None:\n",
    "            next_page,index = find_next_with_index(i,lst,len(file))\n",
    "            if prev!= None:\n",
    "                for j in range(i,index):\n",
    "                    lst[j] = int((next_page -  prev)*(j-i+1) / (index-i+1) + prev)\n",
    "            else:\n",
    "                for j in range(i,index):\n",
    "                    lst[j] = int((next_page-start_pos)*(j-i) / (index-i) + start_pos)                \n",
    "        else:\n",
    "            prev = lst[i]\n",
    "    return lst\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "count how many words in a section\n",
    "'''\n",
    "def check_num_word(pages,tmp_file):\n",
    "    word_count = []\n",
    "    for index in range(len(pages)-1):\n",
    "        previ = pages[index]\n",
    "        nexti = pages[index+1]\n",
    "        count = 0\n",
    "        for l in range(previ,nexti):\n",
    "            line = tmp_file[l].split(\" \")\n",
    "            line = [i for i in line if i!=\"\" and i!=\" \"]\n",
    "            count += len(line)\n",
    "        word_count.append(count)\n",
    "    return word_count\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "check the gold standard summary comes from which part\n",
    "'''\n",
    "toc_key_lst = [\"chief\",\"chairman\",\"highlight\",\"start\",\"glance\",\"executive\"]\n",
    "sections = 0\n",
    "from collections import Counter\n",
    "def count_repeat(sentence,section):\n",
    "    count = 0\n",
    "    for i in sentence.split(\" \"):\n",
    "        if i in section:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def find_where_majority_comefrom(lst): \n",
    "    c = Counter(lst) \n",
    "    if c.most_common(1)[0][1] > int(len(lst)*2/3):\n",
    "        return True,[c.most_common(1)[0][0]]  \n",
    "    lst = [c.most_common(2)[0][0],c.most_common(2)[1][0]]\n",
    "    if 0 in lst and 1 in lst:\n",
    "        return False,[0,1]\n",
    "    #TODO:improve here\n",
    "    else:\n",
    "        #return None\n",
    "        return False,[c.most_common(1)[0][0]]\n",
    "    \n",
    "    \n",
    "def summary_lookup(read_file,report,pages):\n",
    "    tmp_file = []\n",
    "    word_count = 0\n",
    "    with open(read_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.replace(\"\\n\",\"\").replace(\"\\t\",\" \").replace(\"\\xa0\",\" \")\n",
    "            if line==\"\":\n",
    "                continue\n",
    "            tmp_file.append(line)\n",
    "            word_count += len(line.split(\" \"))\n",
    "    if tmp_file==[]:\n",
    "        return None,0\n",
    "    result = []\n",
    "    for sentence in tmp_file:\n",
    "        max_count = 0\n",
    "        pos = 0\n",
    "        for index in range(len(pages)-1):\n",
    "            previ = pages[index]\n",
    "            nexti = pages[index+1]\n",
    "            num = count_repeat(sentence,\" \".join(report[previ:nexti]))\n",
    "            if num>max_count:\n",
    "                max_count = num\n",
    "                pos = index\n",
    "        num = count_repeat(sentence,\" \".join(report[nexti:]))\n",
    "        if num>max_count:\n",
    "            max_count = num\n",
    "            pos = index \n",
    "        result.append(pos)\n",
    "    return find_where_majority_comefrom(result),word_count\n",
    "        \n",
    "def check_summary_of_one_file(file,report,pages,toc):\n",
    "    path = 'train_origin/gold_summaries/'\n",
    "    files = []\n",
    "    file = file.replace(\".txt\",\"\")\n",
    "    global hit_key_word\n",
    "    for i in os.listdir(path):\n",
    "        if os.path.isfile(os.path.join(path,i)) and file==i.split(\"_\")[0]:\n",
    "            files.append(path+i)\n",
    "    smallest_word_count = float(\"inf\")\n",
    "    pos_section = None\n",
    "    final_c = 0\n",
    "    bool_regular_toc = False\n",
    "    zero_one_file = 0\n",
    "    \n",
    "    iflimit = False\n",
    "    global sections\n",
    "    for read_file in files:\n",
    "        pos,c = summary_lookup(read_file,report,pages)\n",
    "        if pos == None:\n",
    "            continue\n",
    "        limit,pos = pos\n",
    "        if pos:\n",
    "            if limit:\n",
    "                iflimit = True\n",
    "            if len(pos)>1:\n",
    "                val = check_num_word(pages,report)[pos[0]] +check_num_word(pages,report)[pos[1]]\n",
    "            else:  \n",
    "                val = check_num_word(pages,report)[pos[0]]\n",
    "            #ans = pos[0],toc[pos[0]],val\n",
    "            ans = pos\n",
    "            if val < smallest_word_count:\n",
    "                smallest_word_count = val \n",
    "                pos_section = ans,read_file\n",
    "                final_c = c\n",
    "            \n",
    "            if 0 in ans or 1 in ans:\n",
    "                zero_one_file = 1 \n",
    "                \n",
    "            #if(pos[0]<3 or any(i in toc[pos[0]].lower() for i in toc_key_lst)):\n",
    "            if(pos[0]<2):\n",
    "                bool_regular_toc = True\n",
    "    if iflimit:\n",
    "        sections +=1\n",
    "    if(bool_regular_toc):\n",
    "        hit_key_word +=1\n",
    "    return pos_section,zero_one_file\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see which searching method is better\n",
    "def see_which_one_better_title(pages_search_by_number,pages_search_by_title,tmp_file,key,start_pos):\n",
    "    exist_page = 0\n",
    "    for i in range(0,min(6,len(pages_search_by_title))):  \n",
    "        if pages_search_by_title[i]!= None:\n",
    "            exist_page += 1 \n",
    "    if exist_page >4:\n",
    "        return True\n",
    "    exist_number = 0\n",
    "    for i in range(0,min(6,len(pages_search_by_number))):\n",
    "        if pages_search_by_number[i]!= None:\n",
    "            exist_number += 1 \n",
    "    if exist_page <= 3 and exist_number >4:\n",
    "        return False\n",
    "    pages_search_by_number = split_into_half(pages_search_by_number,tmp_file,start_pos)\n",
    "    pages_search_by_title = split_into_half(pages_search_by_title,tmp_file,start_pos)\n",
    "    \n",
    "    max_diff_number = 0\n",
    "    bad_times = 0\n",
    "    for i in range(1,min(6,len(pages_search_by_number))):\n",
    "        val = pages_search_by_number[i]-pages_search_by_number[i-1] \n",
    "        if val<3:\n",
    "            bad_times += 1 \n",
    "        if bad_times>1:\n",
    "            return True\n",
    "        if((int(key[i])-int(key[i-1]))==0):\n",
    "            continue\n",
    "        val = val / (int(key[i])-int(key[i-1]))\n",
    "        if val>max_diff_number:\n",
    "            max_diff_number = val\n",
    "            \n",
    "    max_diff_title = 0\n",
    "    bad_times = 0\n",
    "    for i in range(1,min(6,len(pages_search_by_title))):\n",
    "        val = pages_search_by_title[i]-pages_search_by_title[i-1]\n",
    "        if val<3:\n",
    "            bad_times += 1 \n",
    "        if bad_times>1:\n",
    "            return False\n",
    "        if((int(key[i])-int(key[i-1]))==0):\n",
    "            continue\n",
    "        val = val / (int(key[i])-int(key[i-1]))\n",
    "        if val>max_diff_title:\n",
    "            max_diff_title = val\n",
    "    return max_diff_title < max_diff_number*1.2\n",
    "            \n",
    "def see_which_one_better(pages_search_by_number,pages_search_by_title,tmp_file,key,start_pos):\n",
    "    exist_number = 0\n",
    "    for i in range(0,min(6,len(pages_search_by_number))):\n",
    "        if pages_search_by_number[i]!= None:\n",
    "            exist_number += 1 \n",
    "    exist_page = 0\n",
    "    for i in range(0,min(6,len(pages_search_by_title))):  \n",
    "        if pages_search_by_title[i]!= None:\n",
    "            exist_page += 1 \n",
    "    if exist_page <= 3 and exist_number >4:\n",
    "        return True\n",
    "    elif exist_page > 4 and exist_number <=3:\n",
    "        return False\n",
    "    pages_search_by_number = split_into_half(pages_search_by_number,tmp_file,start_pos)\n",
    "    pages_search_by_title = split_into_half(pages_search_by_title,tmp_file,start_pos)\n",
    "\n",
    "    max_diff_number = 0\n",
    "    bad_times = 0\n",
    "    for i in range(1,min(6,len(pages_search_by_number))):\n",
    "        val = pages_search_by_number[i]-pages_search_by_number[i-1] \n",
    "        if val<3:\n",
    "            bad_times += 1 \n",
    "        if bad_times>1:\n",
    "            return False\n",
    "        if((int(key[i])-int(key[i-1]))==0):\n",
    "            continue\n",
    "        val = val / (int(key[i])-int(key[i-1]))\n",
    "        if val>max_diff_number:\n",
    "            max_diff_number = val\n",
    "\n",
    "    max_diff_title = 0\n",
    "    bad_times = 0\n",
    "    for i in range(1,min(6,len(pages_search_by_title))):\n",
    "        val = pages_search_by_title[i]-pages_search_by_title[i-1]\n",
    "        if val<3:\n",
    "            bad_times += 1 \n",
    "        if bad_times>1:\n",
    "            return True\n",
    "        if((int(key[i])-int(key[i-1]))==0):\n",
    "            continue\n",
    "        val = val / (int(key[i])-int(key[i-1]))\n",
    "        if val>max_diff_title:\n",
    "            max_diff_title = val\n",
    "    return max_diff_number < max_diff_title*1.2\n",
    "\n",
    "def page_exist(toc_page):\n",
    "    for i in toc_page:\n",
    "        if i==\"\":\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[86, 93, 117, 266, 1105, 1313, 1825, 3176, None, 4516, 5218, 6071, 6559, None]\n",
      "[None, 119, 172, 267, 285, 301, 2983, 3177, 3415, 4604, 4639, 4686, 4718, 4751]\n",
      "True\n",
      "[86, 93, 117, 266, 1105, 1313, 1825, 3176, 3846, 4516, 5218, 6071, 6559, 6756]\n",
      "['Operational & Financial highlights', 'Chairman ’ s statement', 'Conviviality at a glance', 'Chief Executive Officer ’ s statement', 'Our customers', 'Our suppliers', 'Board of Directors', 'Corporate governance report', 'Remuneration Committee report', 'Consolidated statement of profit or loss', 'Consolidated statement of financial position', 'Consolidated statement of changes in equity', 'Consolidated statement of cash flows', 'Notes to the financial statements']\n",
      "[1]\n",
      "0\n",
      "1\n",
      "1\n",
      "1.0\n",
      "1\n",
      "1.0\n",
      "1\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "directory = \"validation_check/annual_reports/\"\n",
    "bad_file = [\"7796.txt\",\"14018.txt\",\"23372.txt\",\"4842.txt\",\"11692.txt\",\"2633.txt\",\"132.txt\",\"18103.txt\",\"9588.txt\",\"11736.txt\",\"6586.txt\"]\n",
    "\n",
    "total = 0\n",
    "num_file = 0\n",
    "exist_toc = 0\n",
    "\n",
    "find_page = 0\n",
    "all_page = 0\n",
    "\n",
    "hit_key_word = 0\n",
    "word_count = []\n",
    "gold_lst = []\n",
    "target_section = 0\n",
    "bad_file_count = 0\n",
    "\n",
    "zero_one_file = 0\n",
    "zero_one_lst = []\n",
    "#for file has ToC\n",
    "#for file in os.listdir(directory):\n",
    "for file in [\"32092.txt\"]:\n",
    "    if file in bad_file:\n",
    "        continue\n",
    "    if \".DS_Store\" in file:\n",
    "        continue\n",
    "    tmp_file = []\n",
    "    contents = []\n",
    "\n",
    "    with open(os.path.join(directory,file), \"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.replace(\"\\n\",\"\").replace(\"\\t\",\" \").replace(\"\\xa0\",\" \")\n",
    "            tmp_file.append(line)\n",
    "    #I assume that toc will appear in either start or end of the file--> not true\n",
    "    #contain keywords \"content\"\n",
    "    count = 0\n",
    "    find = 0\n",
    "    toc = None\n",
    "    while(count<len(tmp_file)): \n",
    "        if_start,pos = toc_start(tmp_file[count])\n",
    "        if if_start:\n",
    "            toc,start_pos,toc_page = process(count,tmp_file,pos)\n",
    "            if(toc):\n",
    "                find = 1\n",
    "                contents.append(toc)\n",
    "                exist_toc +=1\n",
    "                break\n",
    "        count +=1\n",
    "    count = 0 \n",
    "    while(count<len(tmp_file) and find==0):\n",
    "        if \"contents\" in tmp_file[count].lower():\n",
    "            toc,start_pos,toc_page = process_tolerant(count,tmp_file)\n",
    "            if(toc):\n",
    "                find = 1\n",
    "                contents.append(toc)\n",
    "                exist_toc +=1\n",
    "                break \n",
    "        count +=1\n",
    "    if(find==0):\n",
    "        print(file)\n",
    "    else:\n",
    "        if(page_exist(toc_page)):\n",
    "            pages_search_by_number = search_page(toc_page,tmp_file,start_pos)\n",
    "            print(pages_search_by_number)\n",
    "            pages_search_by_title = split_page(toc,tmp_file,start_pos,toc_page)\n",
    "            #print(pages_search_by_title)\n",
    "            pages_search_by_title = weak_search(toc,pages_search_by_title,tmp_file,start_pos)\n",
    "            print(pages_search_by_title)\n",
    "            ans = see_which_one_better(pages_search_by_number,pages_search_by_title,tmp_file,toc_page,start_pos)\n",
    "            print(ans)\n",
    "            if(ans):\n",
    "                previ = 0 \n",
    "                nexti = 0\n",
    "                for i in range(len(pages_search_by_number)):\n",
    "                    if pages_search_by_number[i]==None and pages_search_by_title[i]!=None:\n",
    "                        nexti = find_next(i,pages_search_by_number,len(tmp_file))\n",
    "                        if (previ < pages_search_by_title[i] and nexti > pages_search_by_title[i]):\n",
    "                            pages_search_by_number[i] = pages_search_by_title[i]\n",
    "                    else:\n",
    "                        if pages_search_by_number[i]!=None:\n",
    "                            previ = pages_search_by_number[i]\n",
    "\n",
    "                pages = pages_search_by_number\n",
    "            else:\n",
    "                pages = pages_search_by_title\n",
    "        else:\n",
    "            pages_search_by_title = split_page_without_pagehint(toc,tmp_file,start_pos)\n",
    "            pages = weak_search(toc,pages_search_by_title,tmp_file)\n",
    "        pages = split_into_half(pages,tmp_file,start_pos)\n",
    "        if abs(start_pos - pages[0]) >100:\n",
    "            pages.insert(0,start_pos)\n",
    "            toc.insert(0,\"start\")\n",
    "        #print(check_num_word(pages,tmp_file))\n",
    "        #print(len(tmp_file))\n",
    "        print(pages)\n",
    "        print(toc)\n",
    "        val = check_summary_of_one_file(file,tmp_file,pages,toc)\n",
    "        if val[0] == None:\n",
    "            bad_file_count +=1\n",
    "            continue\n",
    "        else:\n",
    "            \n",
    "            val,find_01 = val\n",
    "            val, summary_file = val\n",
    "            print(val)\n",
    "            if find_01:\n",
    "                zero_one_file += 1 \n",
    "            else:\n",
    "                zero_one_lst.append(val)\n",
    "                if val[0]==2:\n",
    "                    print(file)\n",
    "            #gold_lst.append([file,val,summary_file.replace(\"validation_check/gold_summaries/\",\"\")])\n",
    "            '''\n",
    "            file1 = open(\"valid_toc_annual_report/\"+file,\"a\")\n",
    "            for i in val:\n",
    "                for j in range(pages[i],pages[i+1]):\n",
    "                    file1.write(tmp_file[j]+\"\\n\") \n",
    "            file1.close() \n",
    "            newPath = shutil.copy(summary_file, 'valid_toc_summary/')\n",
    "            '''\n",
    "\n",
    "    #print(\"***\")\n",
    "    num_file += 1\n",
    "'''\n",
    "print(find_page)\n",
    "print(all_page)\n",
    "print(find_page*1.0/all_page)\n",
    "print(\"*******\")\n",
    "'''\n",
    "#print(target_section)\n",
    "#print(target_section* 1.0/num_file)\n",
    "print(bad_file_count)\n",
    "print(num_file)\n",
    "print(exist_toc)\n",
    "print(exist_toc * 1.0/num_file)\n",
    "\n",
    "print(hit_key_word)\n",
    "print(hit_key_word * 1.0/num_file)\n",
    "\n",
    "print(zero_one_file)\n",
    "print(zero_one_file * 1.0/num_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7386.txt\n",
      "can't find toc: 15362.txt\n",
      "13349.txt\n",
      "18615.txt\n",
      "16837.txt\n",
      "16836.txt\n",
      "number of secion has 2/3 sentence: 2761\n",
      "0\n",
      "2987\n",
      "2984\n",
      "0.9989956478071644\n",
      "2612\n",
      "0.8744559758955474\n"
     ]
    }
   ],
   "source": [
    "#toc first searching\n",
    "directory = \"train_origin/annual_reports/\"\n",
    "bad_file = [\"7796.txt\",\"14018.txt\",\"23372.txt\",\"4842.txt\",\"11692.txt\",\"2633.txt\",\"132.txt\",\"18103.txt\",\"9588.txt\",\"11736.txt\",\"6586.txt\"]\n",
    "\n",
    "sections = 0\n",
    "\n",
    "total = 0\n",
    "num_file = 0\n",
    "exist_toc = 0\n",
    "\n",
    "find_page = 0\n",
    "all_page = 0\n",
    "\n",
    "hit_key_word = 0\n",
    "word_count = []\n",
    "gold_lst = []\n",
    "target_section = 0\n",
    "bad_file_count = 0\n",
    "\n",
    "zero_one_file = 0\n",
    "zero_one_lst = []\n",
    "\n",
    "gold = []\n",
    "#for file has ToC\n",
    "for file in os.listdir(directory):\n",
    "    if file in bad_file:\n",
    "        continue\n",
    "    if \".DS_Store\" in file:\n",
    "        continue\n",
    "    tmp_file = []\n",
    "    contents = []\n",
    "\n",
    "    with open(os.path.join(directory,file), \"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.replace(\"\\n\",\"\").replace(\"\\t\",\" \").replace(\"\\xa0\",\" \")\n",
    "            tmp_file.append(line)\n",
    "    #I assume that toc will appear in either start or end of the file--> not true\n",
    "    #contain keywords \"content\"\n",
    "    count = 0\n",
    "    find = 0\n",
    "    toc = None\n",
    "    while(count<len(tmp_file)): \n",
    "        if_start,pos = toc_start(tmp_file[count])\n",
    "        if if_start:\n",
    "            toc,start_pos,toc_page = process(count,tmp_file,pos)\n",
    "            if(toc):\n",
    "                find = 1\n",
    "                contents.append(toc)\n",
    "                exist_toc +=1\n",
    "                break\n",
    "        count +=1\n",
    "    count = 0 \n",
    "    while(count<len(tmp_file) and find==0):\n",
    "        if \"contents\" in tmp_file[count].lower():\n",
    "            toc,start_pos,toc_page = process_tolerant(count,tmp_file)\n",
    "            if(toc):\n",
    "                find = 1\n",
    "                contents.append(toc)\n",
    "                exist_toc +=1\n",
    "                break \n",
    "        count +=1\n",
    "    if(find==0):\n",
    "        print(file)\n",
    "    else:\n",
    "        if(page_exist(toc_page)):\n",
    "            pages_search_by_number = search_page(toc_page,tmp_file,start_pos)\n",
    "            #print(pages_search_by_number)\n",
    "            pages_search_by_title = split_page(toc,tmp_file,start_pos,toc_page)\n",
    "            #print(pages_search_by_title)\n",
    "            ans = see_which_one_better_title(pages_search_by_number,pages_search_by_title,tmp_file,toc_page,start_pos)\n",
    "            #print(ans)\n",
    "            if(ans):\n",
    "                pages_search_by_title = weak_search(toc,pages_search_by_title,tmp_file,start_pos)\n",
    "                previ = 0 \n",
    "                nexti = 0\n",
    "                for i in range(len(pages_search_by_title)):\n",
    "                    if pages_search_by_title[i]==None and pages_search_by_number[i]!=None:\n",
    "                        nexti = find_next(i,pages_search_by_title,len(tmp_file))\n",
    "                        if (previ < pages_search_by_number[i] and nexti > pages_search_by_number[i]):\n",
    "                            pages_search_by_title[i] = pages_search_by_number[i]\n",
    "                    else:\n",
    "                        if pages_search_by_title[i]!=None:\n",
    "                            previ = pages_search_by_title[i]\n",
    "\n",
    "                pages = pages_search_by_title\n",
    "            else:\n",
    "                pages = pages_search_by_number\n",
    "        elif(page_exist(toc)):\n",
    "            pages_search_by_title = split_page_without_pagehint(toc,tmp_file,start_pos)\n",
    "            pages = weak_search(toc,pages_search_by_title,tmp_file,start_pos)\n",
    "        else:\n",
    "            print(\"can't find toc\",file)\n",
    "            \n",
    "        if len(pages)<1:\n",
    "            print(\"can't find toc: \"+file)\n",
    "            continue\n",
    "        pages = split_into_half(pages,tmp_file,start_pos)\n",
    "        if abs(start_pos - pages[0]) >100:\n",
    "            pages.insert(0,start_pos)\n",
    "            toc.insert(0,\"start\")\n",
    "        #print(check_num_word(pages,tmp_file))\n",
    "        #print(len(tmp_file))\n",
    "        try:\n",
    "            val = check_summary_of_one_file(file,tmp_file,pages,toc)\n",
    "        except:\n",
    "            continue\n",
    "        if val[0] == None:\n",
    "            print(\"no gold section: \"+file)\n",
    "            bad_file_count +=1\n",
    "            continue\n",
    "        else:\n",
    "            \n",
    "            val,find_01 = val\n",
    "            val,summary_file = val\n",
    "            \n",
    "            '''\n",
    "            file1 = open(\"valid_report/\"+file,\"a\")\n",
    "            \n",
    "            for i in val:\n",
    "                for j in range(pages[i],pages[i+1]):\n",
    "                    file1.write(tmp_file[j]+\"\\n\") \n",
    "            file1.close() \n",
    "            newPath = shutil.copy(summary_file, 'valid_summary/')          \n",
    "            '''\n",
    "            '''\n",
    "            for i in range(len(pages)-1):\n",
    "                file1 = open(\"train_1/\"+file.split(\".\")[0]+\"_\"+str(i)+\".txt\",\"a\")\n",
    "                for j in range(pages[i],pages[i+1]):\n",
    "                    file1.write(tmp_file[j]+\"\\n\") \n",
    "                file1.close() \n",
    "            '''\n",
    "            #gold.append([file,val])\n",
    "            \n",
    "            '''\n",
    "            file1 = open(\"valid_report_selected/\"+file,\"a\")\n",
    "            selected = []\n",
    "            for i in val:\n",
    "                for j in range(pages[i],pages[i+1]):\n",
    "                    selected.append(tmp_file[j])\n",
    "            gold_summary_sentencefilter(summary_file,selected)\n",
    "\n",
    "            for content in gold_summary_sentencefilter(summary_file,selected):\n",
    "                file1.write(content+\"\\n\") \n",
    "            file1.close() \n",
    "            newPath = shutil.copy(summary_file, 'valid_gold_selected/')\n",
    "            '''    \n",
    "    num_file += 1\n",
    "#dump_json(gold)\n",
    "#print(target_section)\n",
    "#print(target_section* 1.0/num_file)\n",
    "print(\"number of secion has 2/3 sentence: \"+str(sections))\n",
    "print(bad_file_count)\n",
    "print(num_file)\n",
    "print(exist_toc)\n",
    "print(exist_toc * 1.0/num_file)\n",
    "\n",
    "print(hit_key_word)\n",
    "print(hit_key_word * 1.0/num_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get sentence from the selectioin section which appear in the gold summary:\n",
    "\n",
    "def gold_summary_sentencefilter(read_file,pages):\n",
    "    tmp_file = []\n",
    "    with open(read_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.replace(\"\\n\",\"\").replace(\"\\t\",\" \").replace(\"\\xa0\",\" \")\n",
    "            if line==\"\":\n",
    "                continue\n",
    "            tmp_file.append(line)\n",
    "    tmp_file = \" \".join(tmp_file)\n",
    "    result = []\n",
    "    \n",
    "    pos = 0\n",
    "    pos_lst = []\n",
    "    for i in pages:\n",
    "        num = count_repeat(i,tmp_file)\n",
    "        if num>(len(i.split(\" \"))/2):\n",
    "            result.append(i)\n",
    "            pos_lst.append(pos)\n",
    "        pos += 1 \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_json(lst):\n",
    "    with open('val_gold.json', 'w') as f:\n",
    "        json.dump(lst, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32859.txt\n",
      "32865.txt\n",
      "31955.txt\n",
      "32197.txt\n",
      "32236.txt\n",
      "31685.txt\n",
      "31220.txt\n",
      "352\n",
      "352\n"
     ]
    }
   ],
   "source": [
    "toc_search = []\n",
    "for file in os.listdir(\"valid_toc_search_report\"):\n",
    "    toc_search.append(file)\n",
    "\n",
    "    \n",
    "files = []\n",
    "for file in os.listdir(\"valid_toc_annual_report\"):\n",
    "    files.append(file)\n",
    "    if file not in toc_search:\n",
    "        print(file)\n",
    "        #newPath = shutil.copy(file, 'valid_toc_search_report/')\n",
    "print(len(toc_search))\n",
    "print(len(files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "363\n",
      "363\n",
      "1.0\n",
      "0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#only use section 0,1 as output:\n",
    "directory = \"validation_check/annual_reports/\"\n",
    "bad_file = [\"7796.txt\",\"14018.txt\",\"23372.txt\",\"4842.txt\",\"11692.txt\",\"2633.txt\",\"132.txt\",\"18103.txt\",\"9588.txt\",\"11736.txt\",\"6586.txt\"]\n",
    "\n",
    "total = 0\n",
    "num_file = 0\n",
    "exist_toc = 0\n",
    "\n",
    "find_page = 0\n",
    "all_page = 0\n",
    "\n",
    "hit_key_word = 0\n",
    "word_count = []\n",
    "\n",
    "target_section = 0\n",
    "bad_file_count = 0\n",
    "#for file has ToC\n",
    "for file in os.listdir(directory):\n",
    "#for file in [\"30849.txt\"]:\n",
    "    if file in bad_file:\n",
    "        continue\n",
    "    if \".DS_Store\" in file:\n",
    "        continue\n",
    "    tmp_file = []\n",
    "    contents = []\n",
    "\n",
    "    with open(os.path.join(directory,file), \"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.replace(\"\\n\",\"\").replace(\"\\t\",\" \").replace(\"\\xa0\",\" \")\n",
    "            tmp_file.append(line)\n",
    "    #I assume that toc will appear in either start or end of the file--> not true\n",
    "    #contain keywords \"content\"\n",
    "    count = 0\n",
    "    find = 0\n",
    "    toc = None\n",
    "    while(count<len(tmp_file)): \n",
    "        if_start,pos = toc_start(tmp_file[count])\n",
    "        if if_start:\n",
    "            toc,start_pos,toc_page = process(count,tmp_file,pos)\n",
    "            if(toc):\n",
    "                find = 1\n",
    "                contents.append(toc)\n",
    "                exist_toc +=1\n",
    "                break\n",
    "        count +=1\n",
    "    count = 0 \n",
    "    while(count<len(tmp_file) and find==0):\n",
    "        if \"contents\" in tmp_file[count].lower():\n",
    "            toc,start_pos,toc_page = process_tolerant(count,tmp_file)\n",
    "            if(toc):\n",
    "                find = 1\n",
    "                contents.append(toc)\n",
    "                exist_toc +=1\n",
    "                break \n",
    "        count +=1\n",
    "    if(find==0):\n",
    "        print(file)\n",
    "    else:\n",
    "        if(page_exist(toc_page)):\n",
    "            pages_search_by_number = search_page(toc_page,tmp_file,start_pos)\n",
    "            #print(pages_search_by_number)\n",
    "            pages_search_by_title = split_page(toc,tmp_file,start_pos,toc_page)\n",
    "            #print(pages_search_by_title)\n",
    "            pages_search_by_title = weak_search(toc,pages_search_by_title,tmp_file,start_pos)\n",
    "            #print(pages_search_by_title)\n",
    "            ans = see_which_one_better(pages_search_by_number,pages_search_by_title,tmp_file,toc_page,start_pos)\n",
    "            #print(ans)\n",
    "            #print(len(tmp_file))\n",
    "            if(ans):\n",
    "                previ = 0 \n",
    "                nexti = 0\n",
    "                for i in range(len(pages_search_by_number)):\n",
    "                    if pages_search_by_number[i]==None and pages_search_by_title[i]!=None:\n",
    "                        nexti = find_next(i,pages_search_by_number,len(tmp_file))\n",
    "                        if (previ < pages_search_by_title[i] and nexti > pages_search_by_title[i]):\n",
    "                            pages_search_by_number[i] = pages_search_by_title[i]\n",
    "                    else:\n",
    "                        if pages_search_by_number[i]!=None:\n",
    "                            previ = pages_search_by_number[i]\n",
    "\n",
    "                pages = pages_search_by_number\n",
    "            else:\n",
    "                pages = pages_search_by_title\n",
    "        else:\n",
    "            pages_search_by_title = split_page_without_pagehint(toc,tmp_file,start_pos)\n",
    "            pages = weak_search(toc,pages_search_by_title,tmp_file,start_pos)\n",
    "        pages = split_into_half(pages,tmp_file,start_pos)\n",
    "        if abs(start_pos - pages[0]) >50:\n",
    "            pages.insert(0,start_pos)\n",
    "            toc.insert(0,\"start\")\n",
    "        #print(check_num_word(pages,tmp_file))\n",
    "        #print(len(tmp_file))\n",
    "        #first two sections\n",
    "        for i in range(len(pages)-1):\n",
    "            file1 = open(\"val_annual_report_all_sections/\"+file.split(\".\")[0]+\"_\"+str(i)+\".txt\",\"a\")\n",
    "            for j in range(pages[i],pages[i+1]):\n",
    "                file1.write(tmp_file[j]+\"\\n\") \n",
    "            file1.close() \n",
    "        '''\n",
    "        generate section 0 and 1\n",
    "        for i in [0,1]:\n",
    "            for j in range(pages[i],pages[i+1]):\n",
    "                file1.write(tmp_file[j]+\"\\n\") \n",
    "        file1.close() \n",
    "        \n",
    "        \n",
    "        generate top 1000 words\n",
    "        file1 = open(\"valid_toc_annual_report_1000/\"+file,\"a\")\n",
    "        len_sec = 0\n",
    "        i = 0\n",
    "        while(len_sec<=1000 and i<len(pages)-1):\n",
    "            for j in range(pages[i],pages[i+1]):\n",
    "                len_sec += len(tmp_file[j].split(\" \"))\n",
    "                file1.write(tmp_file[j]+\"\\n\") \n",
    "            i += 1\n",
    "        file1.close() \n",
    "        '''\n",
    "        #newPath = shutil.copy(summary_file, 'valid_toc_summary/')\n",
    "       \n",
    "\n",
    "    #print(\"***\")\n",
    "    num_file += 1\n",
    "\n",
    "'''\n",
    "print(find_page)\n",
    "print(all_page)\n",
    "print(find_page*1.0/all_page)\n",
    "print(\"*******\")\n",
    "'''\n",
    "#print(target_section)\n",
    "#print(target_section* 1.0/num_file)\n",
    "print(bad_file_count)\n",
    "print(num_file)\n",
    "print(exist_toc)\n",
    "print(exist_toc * 1.0/num_file)\n",
    "\n",
    "print(hit_key_word)\n",
    "print(hit_key_word * 1.0/num_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9203333333333333\n"
     ]
    }
   ],
   "source": [
    "directory = \"train_origin/annual_reports/\"\n",
    "count = 0\n",
    "for file in os.listdir(directory):\n",
    "    if \"txt\" in file:\n",
    "        count += 1\n",
    "print(2761.0/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
